{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation visuelle pour reconstruction d'image corporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "L'objectif est d'améliorer le code de network2_01.py. \n",
    "Plusieurs pistes d'amélioration sont possibles:\n",
    "1. Utiliser un produit tensoriel plutôt qu'un produit terme à terme.\n",
    "2. Différencier la cible de la main.\n",
    "3. Intégerer tf.\n",
    "4. changer la répartition des points. \n",
    "\n",
    "Je m'inspire de l'article de Memisevic, Gradient-based learning of higher-order image features et de son code gatedAutoencoder.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et setup\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from matplotlib.pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from drawnow import *\n",
    "from skimage.draw import line, line_aa\n",
    "\n",
    "import time \n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import cv2\n",
    "import cPickle as pickle\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size':16})\n",
    "to_backup = True\n",
    "timeframe = time.strftime('%Y%m%d%H%M%S')\n",
    "L1 = 16\n",
    "L2 = 8\n",
    "L3 = 1\n",
    "\n",
    "nb_posture = 300\n",
    "nb_command = 100\n",
    "nb_joint = 3\n",
    "nb_data = nb_command*nb_posture\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On génère n postures différentes aléatoirement, X.\n",
    "2. On génère m commandes aléatoirement, H. \n",
    "3. On applique chaque commande à chaque posture et on obtient des nouvelles postures Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des postures initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randrange(n , vmin, vmax):\n",
    "    return (vmax-vmin)*rand(n) + vmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posture = zeros((nb_posture, 3))\n",
    "posture[:,0] = randrange(nb_posture, 0, pi)\n",
    "posture[:,1] = randrange(nb_posture, 0, pi)\n",
    "posture[:,2] =randrange(nb_posture, 0, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "[1.2425477  0.85738005 0.62610169]\n"
     ]
    }
   ],
   "source": [
    "print(shape(posture))\n",
    "print(posture[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des commandes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = zeros((nb_command, 3))\n",
    "command[:,0] = randrange(nb_command, 0, 1)*0.3\n",
    "command[:,1] = randrange(nb_command, 0, 1)*0.3\n",
    "command[:,2] = 0 #randrange(nb_command, 0, 1)*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[0.27401548 0.26732346 0.        ]\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "print(shape(command))\n",
    "print(command[0])\n",
    "print(randint(0,nb_command-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = zeros((nb_data, 1, 3))\n",
    "train_data_y = zeros((nb_data, 1, 3))\n",
    "train_data_h = zeros((nb_data, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "(30000, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x[0][0])\n",
    "print(shape(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_x[idx] = posture[i]\n",
    "        idx = idx + 1\n",
    "\n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_y[idx] = posture[i]  + command[j]\n",
    "        idx = idx + 1\n",
    "        \n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_h[idx] = command[j]\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data_x 0 0 ', array([1.2425477 , 0.85738005, 0.62610169]))\n",
      "('train_data_h 0 0 ', array([0.27401548, 0.26732346, 0.        ]))\n",
      "('train_data_y 0 0 ', array([1.51656318, 1.12470351, 0.62610169]))\n",
      "y = x + h\n"
     ]
    }
   ],
   "source": [
    "print('train_data_x 0 0 ', train_data_x[0][0])\n",
    "print('train_data_h 0 0 ', train_data_h[0][0])\n",
    "print('train_data_y 0 0 ', train_data_y[0][0])\n",
    "print('y = x + h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des images associées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_x = zeros((nb_data, 1, img_size, img_size ), dtype = float32)\n",
    "train_images_y = zeros((nb_data, 1, img_size, img_size ), dtype = float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_x[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    #r1, c1 = line(img_size//2,img_size//2,row1, col1)\n",
    "    #r2, c2 = line(row1, col1, row2, col2)\n",
    "    #r3, c3 = line(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_x[i][0] = img / 255.\n",
    "\n",
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_y[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    #r1, c1 = line(img_size//2,img_size//2,row1, col1)\n",
    "    #r2, c2 = line(row1, col1, row2, col2)\n",
    "    #r3, c3 = line(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_y[i][0] = img / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille train_images_x', (30000, 1, 64, 64))\n",
      "('taille train_images_y', (30000, 1, 64, 64))\n",
      "('taille train_features', (30000, 2, 64, 64))\n"
     ]
    }
   ],
   "source": [
    "print('taille train_images_x', shape(train_images_x))\n",
    "print('taille train_images_y', shape(train_images_y))\n",
    "train_features = concatenate((train_images_x, train_images_y), 1)\n",
    "print('taille train_features', shape(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut rajouter une gaussienne au bout de l'effecteur pour le mettre en évidence\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "    x = arange(0, size, 1, float)\n",
    "    y = x[:,newaxis]\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]    \n",
    "    return exp(-4*log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd9210f5490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd92100ea90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAECCAYAAAAcpHkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAADXxJREFUeJzt3X+o3fV9x/HnOzMmRs1MqIyZmNqw6jA4OwhUiOCSgnGi0WEF3bCt0qUtznYrKrWusBXF1clWulZr6lZGYx00ao10WJMaHWyR1YKtpq2dm4066TBL5q/KhvreH9/vDffe9zH33Hu/55wb7/MBh++5n+/n3O/7fJK88vl+z49PZCaSNN6CURcgae4xGCQVBoOkwmCQVBgMkgqDQVLRaTBExIkRsS0iXoqIlyPinohY1eUxJA1edPU+hohYAvwQ+F/gT4EEbgCWAL+Vma91ciBJA3dEh7/rD4HVwCmZ+TRARPwI+DfgY8BfdXgsSQPU5Yzhe8DizFw3qf0RgMw8q5MDSRq4LmcMa4D7erTvAS6e6sFHxqJczNEdliNpslc4sC8zj5+qX5fBsBw40KN9P7Bsqgcv5mjeHx/osBxJk+3MbXv76ddlMExbRGwGNgMsZskoS5E0TpcvVx6g98zg7WYSZOaWzFybmWsXsqjDUiTNRpfBsIfmOsNkpwI/7vA4kgasy2DYDpwREavHGiLiJGBdu0/SYaLLYPga8HPgvoi4ICI20bxK8Rxwe4fHkTRgnQVD+87GDcDPgG8AdwLPABsy89WujiNp8Dp9VSIznwUu6vJ3Sho+P10pqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKkwGCQVBoOkwmCQVBgMkgqDQVJhMEgqDAZJhcEgqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKkwGCQVBoOkwmCQVBgMkgqDQVJhMEgqDAZJhcEgqTAYJBUGg6TCYJBUGAySCoNBUmEwSCqmDIaI+GBE3B0ReyPi9Yh4KiJuiohjJ/VbFhF3RMS+iHgtInZGxGmDK13SoPQzY7gaeBP4LHAOcBvwCWBHRCwAiIgA7m/3XwVcBCwEdkXEygHULWmAjuijz/mZ+eK4nx+JiP3A3wO/AzwEbALWARsycxdAROwGngGuBT7ZZdGSBmvKGcOkUBjz/Xa7ot1uAl4YC4X2cS/RzCIumG2RkoZrphcfz2q3P2m3a4Ane/TbA6yKiGNmeBxJIzDtYIiIFcDngZ2Z+VjbvBw40KP7/na7bGblSRqFfq4xHNT+z38f8AZw+WwPHhGbgc0Ai1ky218nqSN9zxgi4iiaawargY2Z+fy43QfoPStYPm5/kZlbMnNtZq5dyKJ+S5E0YH0FQ0QsBLYBa4FzM/OJSV320FxnmOxU4NnMfHVWVUoaqn7e4LQAuBPYAFyYmY/26LYdWBERZ4173FLg/HafpMNIP9cYvgJcDNwIvBYRZ4zb93x7SrEd2A1sjYhraE4drgMCuLnbkiUNWj+nEr/bbq+n+cc//vZRgMx8CzgP2AHcCtxL827J9Zn5XMc1SxqwKWcMmXlSP78oM/cDV7Q3SYcxP10pqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKkwGCQVBoOkwmCQVBgMkgqDQVJhMEgqDAZJhcEgqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBknFEaMuQIev777w+MH7G0943wgrUdecMUgqDAZJhcEgqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKkwGCQVBoOkwmCQVMwoGCLigYjIiLhhUvuyiLgjIvZFxGsRsTMiTuumVEnDMu1giIhLgdN7tAdwP3AOcBVwEbAQ2BURK2dZp6QhmlYwRMQy4K+BT/fYvQlYB1yWmXdl5gNt2wLg2tkWKml4pjtj+ALwZGbe1WPfJuCFzNw11pCZL9HMIi6YeYmShq3vYIiIM4EPAVe+TZc1wJM92vcAqyLimOmXJ2kU+gqGiDgSuB24JTOfeptuy4EDPdr3t9tl0y9P0ij0u6jttcBRwI1dHjwiNgObARazpMtfLWkWpgyGiFgFXA98FFgUEYvG7V4UEccBr9DMFnrNCpa32zKbyMwtwBaApbE8p1e6pEHp51RiNbAY2Erzj3vsBnB1e/80mmsJa3o8/lTg2cx8ddbVShqKfk4lHgfW92jfRRMWfws8DWwHLo+IszLzEYCIWAqcD3yzm3IlDcOUwZCZ/wM8PLm9eT8TezPz4fbn7cBuYGtEXEMzk7gOCODmziqWNHCdfVYiM98CzgN2ALcC9wJvAusz87mujiNp8Pp9VaLIzOjRth+4or1JOkz56UpJhcEgqTAYJBUGg6TCYJBUGAySCoNBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSMePvY5DGO2Lligk/v/H8f46oEnXBGYOkwmCQVHgqoRk7+ZEPH7yffzRxwaDVn/FU4nDmjEFSYTBIKgwGSYXXGDRjK7++8OD9zX/zDxP2ff0z7x52OeqQMwZJhcEgqfBUQjO28MHHDt7/9r7fnrDvxY+fcvD+8V/dPbSa1A1nDJIKg0FSYTBIKrzGoE787BunTPj55MueOnj/wFeHXY1myxmDpMJgkFR4KqFOTH5J8sI/2Xvw/pazL5qwb/zLnJqbnDFIKgwGSYXBIKnwGoMG4nP3XnLwflz+ywn73vPgsKvRdDljkFQYDJIKTyU0ECd/+dmD97/zr9+ZsG8j7xt2OZomZwySCoNBUuGphAZi/BJ1G0/w1OFw44xBUmEwSCoMBkmFwSCpMBgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKnoOxgi4tyI+KeIeDUiXo6IxyJiw7j9yyLijojYFxGvRcTOiDhtMGVLGqS+giEiPgbcB/wA+D3gYuBbwJJ2fwD3A+cAVwEXAQuBXRGxsvuyJQ3SlB+7joiTgC8C12TmF8ft+u64+5uAdcCGzNzVPm438AxwLfDJjuqVNAT9zBiuAN4CDrU06SbghbFQAMjMl2hmERfMqkJJQ9dPMJwJ/BS4JCL+PSLeiIinI+LKcX3WAE/2eOweYFVEHNNBrZKGpJ9gOAF4L/CXwF8AZwM7gC9HxKfaPsuBAz0eu7/dLptlnZKGqJ+vdlsAHAt8JDPvadseaq89XBcRX5rpwSNiM7AZYHFzHVPSHNDPjOG/2+2OSe0PAr8G/DrNbKHXrGB5u+01myAzt2Tm2sxcu5BFfZQiaRj6CYY9U+x/q+2zpse+U4FnM/PV6RYmaXT6CYZ72+3GSe3nAM9n5i+A7cCKiDhrbGdELAXOb/dJOoz0c43hH4FdwO0R8S7gP2je4HQ2cHnbZzuwG9gaEdfQnDpcBwRwc9dFSxqsKYMhMzMiLgRuAv6c5lrCT4E/yMxvtn3eiojzgFuAW4HFNEGxPjOfG1TxkgYjMnPUNQCwNJbn++MDoy5Dekfbmdt+kJlrp+rnpyslFQaDpMJgkFQYDJIKg0FSMWdelYiIF4G9wLuAfSMuZy5xPCZyPCaa7ni8OzOPn6rTnAmGMRHxWD8vp8wXjsdEjsdEgxoPTyUkFQaDpGIuBsOWURcwxzgeEzkeEw1kPObcNQZJozcXZwySRmxOBENEnBgR2yLipXYxm3siYtWo6xq0iPhgRNwdEXsj4vWIeCoiboqIYyf1m7eL+UTEAxGREXHDpPZ5MyajWOxp5MEQEUuAh4DfBD4MXEbz5bO7IuLoUdY2BFcDbwKfpfnim9uATwA7ImIBzO/FfCLiUuD0Hu3zZkxGtthTZo70BnyK5h/Hb4xrew/wBvDpUdc34Od+fI+2DwFJs3gPNOtyJM13W4z1+VWab+D+0qifwwDHZhnwC+DS9vnfMG7fvBgT4CTgdeCPD9FnIGMx8hkDzWI1j2bm02MNmfkM8M+8wxerycwXezR/v92uaLfzdTGfLwBPZuZdPfbNlzEZ2WJPcyEYDrVYzalDrmUuGPvezJ+023m3mE9EnEkzc7rybbrMlzEZ2WJPcyEYDrVYzbxaqCYiVgCfB3Zm5mNt87xazCcijgRuB27JzKfeptt8GZORLfbUz5fBagjaZL+P5trK5VN0fye7FjgKuHHUhcwBA1vsqZ8Dj9qhFqvpuVDNO01EHEVzTrga2JiZz4/bPaPFfA5H7UvU1wOfAxZFxHERcVy7e+znX2H+jMnAFnuaylwIhkMtVvPjIdcydBGxENgGrAXOzcwnJnWZT4v5rKb5hvGtNH+hx27QvLR7ADiN+TMmI1vsaS4Ew3bgjIhYPdbQTpXW8Q5frKZ9r8KdwAbgwsx8tEe3+bSYz+PA+h43aMJiPfA082dMRrfY0xx4rfZomj/sJ2heXtkE/JBmYZtjRl3fgJ/7bbSv0QNnTLqtbPssAP4FeA64pP1L8jDNxaUTR/0chjROk9/HMC/GhGbBpodoTik+TnPx8WvteHxkkGMx8iffPrlVwN3Ay8ArwLeBk0Zd1xCe98/bP+Retz8b12858HftH/Yvge8Bp4+6/iGO04RgmE9jAiwFvgL8F/B/wI+A3x/0WPjpSknFXLjGIGmOMRgkFQaDpMJgkFQYDJIKg0FSYTBIKgwGSYXBIKn4f/Y25x+SNAnDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized Gated Field Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant le passge dans l'autoencodeur, les images sont factorisées en passant par une couche de percpetron. De même, la couche latente est factorisée.\n",
    "Les images sont de taille (128,128), on prend pour commencer 32 neurones. \n",
    "La sortie est de taille (3,1) (trois moteurs), on prend pour commencer une factorisation de taille (32,1) (synérgies motrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc un encodeur, un décodeur et 3 couches de perceptrons pour les deux images et pour les commandes motrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par construire un auto encodeur dont les entrées sont un tenseur de taille (32,1) et de sortie (32,1), pour garder la symétrie de la structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Input, Multiply\n",
    "from keras.layers import Conv2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.layers import Dot, Lambda, Concatenate, RepeatVector\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'encodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(None, 64)\n",
      "('out taille', (None, 1, 128))\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "input_shape = (2, input_size, input_size)\n",
    "latent_dim = 64 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (2, img_size, img_size, ), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,0,:,:])(inputs_xy)\n",
    "x = Reshape((1,img_size, img_size,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,1,:,:])(inputs_xy)\n",
    "y = Reshape((1,img_size, img_size,))(y)\n",
    "\n",
    "# on factorise chacune des images\n",
    "fx = Flatten()(x)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Flatten()(y)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "print(K.int_shape(fh))\n",
    "# on passe des synérgies motrices aux actionneurs\n",
    "#latent = Dense(3, activation = 'sigmoid',  name = 'latent_vector')(fh)\n",
    "#print('taille latent', K.int_shape(latent))\n",
    "\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "fh = Reshape((1,latent_dim,))(fh)\n",
    "#latent = Reshape((1,3,))(latent)\n",
    "\n",
    "out = Concatenate()([fx, fh])\n",
    "print('out taille', K.int_shape(out))\n",
    "\n",
    "encoder = Model(inputs = inputs_xy, outputs = out, name = 'encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille input', (None, 1, 128))\n",
      "('taille fx', (None, 64, 1))\n",
      "('taille tmp', (None, 64))\n",
      "('taille fhdec avant', (None, 64))\n",
      "('taille fhdec apres', (None, 64, 1))\n",
      "('taille matmuldec avant', (None, 64, 1))\n",
      "('taille matmuldec apres', (None, 64))\n",
      "('taille img dec', (None, 1, 64, 64))\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = Input(shape = (1,2*latent_dim,), name = 'decoder_input')\n",
    "print('taille input', K.int_shape(latent_inputs))\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:latent_dim])(latent_inputs)\n",
    "fxdec = Reshape((latent_dim,1,))(fxdec)\n",
    "print('taille fx', K.int_shape(fxdec))\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,latent_dim:])(latent_inputs)\n",
    "inp = Reshape((latent_dim,))(inp)\n",
    "print('taille tmp', K.int_shape(inp))\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(latent_dim, name='latent_fhdec')(inp)\n",
    "print('taille fhdec avant', K.int_shape(fhdec))\n",
    "fhdec = Reshape((latent_dim,1,))(fhdec)\n",
    "print('taille fhdec apres', K.int_shape(fhdec))\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "print('taille matmuldec avant', K.int_shape(matmuldec))\n",
    "matmuldec = Reshape((latent_dim,))(matmuldec)\n",
    "print('taille matmuldec apres', K.int_shape(matmuldec))\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(latent_dim, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(img_size*img_size, activation = 'relu', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((1,img_size, img_size,))(ydec)\n",
    "print('taille img dec', K.int_shape(ydec))\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs= ydec, name='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 2, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1, 128)            528576    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 1, 64, 64)         274560    \n",
      "=================================================================\n",
      "Total params: 803,136\n",
      "Trainable params: 803,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs_xy, decoder(encoder(inputs_xy)), name = \"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre des figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "plot_model(encoder, to_file='encoder.png')\n",
    "plot_model(decoder, to_file = 'decoder.png')\n",
    "plot_model(autoencoder, to_file = 'auto_encoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encodeur alternatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "input_shape = (2, input_size, input_size)\n",
    "latent_dim = 64 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (2, img_size, img_size, ), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,0,:,:])(inputs_xy)\n",
    "x = Reshape((1,img_size, img_size,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,1,:,:])(inputs_xy)\n",
    "y = Reshape((1,img_size, img_size,))(y)\n",
    "\n",
    "# on factorise chacune des images avec dex conv2D\n",
    "fx = Conv2D(filters = 32, kernel_size = 3, strides = 2, activation = 'relu', padding = \"same\")(x)\n",
    "fx = Flatten()(fx)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Conv2D(filters = 32, kernel_size = 3, strides = 2, activation = 'relu', padding = \"same\")(y)\n",
    "fy = Flatten()(fy)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "fh = Reshape((1,latent_dim,))(fh)\n",
    "out = Concatenate()([fx, fh])\n",
    "\n",
    "encoder_alt = Model(inputs = inputs_xy, outputs = out, name = 'encoder_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape = (1,2*latent_dim,), name = 'decoder_input')\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:latent_dim])(latent_inputs)\n",
    "fxdec = Reshape((latent_dim,1,))(fxdec)\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,latent_dim:])(latent_inputs)\n",
    "inp = Reshape((latent_dim,))(inp)\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(latent_dim, name='latent_fhdec')(inp)\n",
    "fhdec = Reshape((latent_dim,1,))(fhdec)\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "matmuldec = Reshape((latent_dim,))(matmuldec)\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(latent_dim, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(img_size*img_size, activation = 'relu', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((1,img_size, img_size,))(ydec)\n",
    "\n",
    "# on rajoute une couche de déconvolution \n",
    "ydec = Conv2DTranspose(filters= 32, kernel_size = 3, activation = 'relu', padding = 'same')(ydec)\n",
    "ydec = Conv2DTranspose(filters= 64, kernel_size = 3, activation = 'relu', padding = 'same')(ydec)\n",
    "decoder_alt = Model(latent_inputs, outputs= ydec, name='decoder_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 2, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "encoder_alt (Model)          (None, 1, 128)            172288    \n",
      "_________________________________________________________________\n",
      "decoder_alt (Model)          (None, 1, 64, 64)         311520    \n",
      "=================================================================\n",
      "Total params: 483,808\n",
      "Trainable params: 483,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_alt = Model(inputs_xy, decoder_alt(encoder_alt(inputs_xy)), name = \"autoencoder_alt\")\n",
    "autoencoder_alt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle sur des pairs d'images.\n",
    "On utilise une descente de gradient stochastique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1000\n",
      "24000/24000 [==============================] - 8s 330us/step - loss: 1.7448 - mean_absolute_error: 0.1829 - acc: 0.0403 - val_loss: 1.6718 - val_mean_absolute_error: 0.2045 - val_acc: 0.0385\n",
      "Epoch 2/1000\n",
      "19360/24000 [=======================>......] - ETA: 1s - loss: 1.6510 - mean_absolute_error: 0.2152 - acc: 0.0376"
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "autoencoder.compile(loss = 'kullback_leibler_divergence', \n",
    "                    optimizer = 'sgd', \n",
    "                    metrics = ['mae', 'acc'])\n",
    "\n",
    "history = autoencoder.fit(train_features,\n",
    "                          train_images_y,\n",
    "                          validation_split = 0.2,\n",
    "                          epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Décodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_decoded = autoencoder.predict(train_features)\n",
    "imshow(x_decoded[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "rows, cols = 10, 30\n",
    "num = rows * cols\n",
    "imgs = np.concatenate([train_images_x[:num], train_images_y[:num], x_decoded[:num]])\n",
    "imgs = imgs.reshape((rows * 3, cols, img_size, img_size))\n",
    "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
    "imgs = imgs.reshape((rows * 3, -1, img_size, img_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "imgs = (imgs *255 ).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Original images: top rows, '\n",
    "          'Corrupted Input: middle rows, '\n",
    "          'Denoised Input:  third rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(x_decoded[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
