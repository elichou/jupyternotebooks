{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation visuelle pour reconstruction d'image corporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "L'objectif est d'améliorer le code de network2_01.py. \n",
    "Plusieurs pistes d'amélioration sont possibles:\n",
    "1. Utiliser un produit tensoriel plutôt qu'un produit terme à terme.\n",
    "2. Différencier la cible de la main.\n",
    "3. Intégerer tf.\n",
    "4. changer la répartition des points. \n",
    "\n",
    "Je m'inspire de l'article de Memisevic, Gradient-based learning of higher-order image features et de son code gatedAutoencoder.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et setup\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from matplotlib.pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from drawnow import *\n",
    "from skimage.draw import line, line_aa\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import time \n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import cv2\n",
    "import cPickle as pickle\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size':16})\n",
    "to_backup = True\n",
    "timeframe = time.strftime('%Y%m%d%H%M%S')\n",
    "L1 = 16\n",
    "L2 = 8\n",
    "L3 = 1\n",
    "\n",
    "nb_posture = 300\n",
    "nb_command = 100\n",
    "nb_joint = 3\n",
    "nb_data = nb_command*nb_posture\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On génère n postures différentes aléatoirement, X.\n",
    "2. On génère m commandes aléatoirement, H. \n",
    "3. On applique chaque commande à chaque posture et on obtient des nouvelles postures Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des postures initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randrange(n , vmin, vmax):\n",
    "    return (vmax-vmin)*rand(n) + vmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posture = zeros((nb_posture, 3))\n",
    "posture[:,0] = randrange(nb_posture, 0, pi)\n",
    "posture[:,1] = randrange(nb_posture, 0, pi)\n",
    "posture[:,2] =randrange(nb_posture, 0, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "[0.35016436 0.90691751 1.34759612]\n"
     ]
    }
   ],
   "source": [
    "print(shape(posture))\n",
    "print(posture[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des commandes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = zeros((nb_command, 3))\n",
    "command[:,0] = randrange(nb_command, 0, 1)*0.3\n",
    "command[:,1] = randrange(nb_command, 0, 1)*0.3\n",
    "command[:,2] = 0 #randrange(nb_command, 0, 1)*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[0.27347536 0.21570526 0.        ]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(shape(command))\n",
    "print(command[0])\n",
    "print(randint(0,nb_command-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = zeros((nb_data, 1, 3))\n",
    "train_data_y = zeros((nb_data, 1, 3))\n",
    "train_data_h = zeros((nb_data, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "(30000, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x[0][0])\n",
    "print(shape(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_x[idx] = posture[i]\n",
    "        idx = idx + 1\n",
    "\n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_y[idx] = posture[i]  + command[j]\n",
    "        idx = idx + 1\n",
    "        \n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_h[idx] = command[j]\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data_x 0 0 ', array([0.35016436, 0.90691751, 1.34759612]))\n",
      "('train_data_h 0 0 ', array([0.27347536, 0.21570526, 0.        ]))\n",
      "('train_data_y 0 0 ', array([0.62363973, 1.12262277, 1.34759612]))\n",
      "y = x + h\n"
     ]
    }
   ],
   "source": [
    "print('train_data_x 0 0 ', train_data_x[0][0])\n",
    "print('train_data_h 0 0 ', train_data_h[0][0])\n",
    "print('train_data_y 0 0 ', train_data_y[0][0])\n",
    "print('y = x + h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des images associées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_x = zeros((nb_data, 1, img_size, img_size ), dtype = float32)\n",
    "train_images_y = zeros((nb_data, 1, img_size, img_size ), dtype = float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_x[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    #r1, c1 = line(img_size//2,img_size//2,row1, col1)\n",
    "    #r2, c2 = line(row1, col1, row2, col2)\n",
    "    #r3, c3 = line(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1 *255\n",
    "    img[r2,c2] = val2 *255\n",
    "    img[r3,c3] = val3 *255\n",
    "    train_images_x[i][0] = gaussian_filter(img , sigma = 2) / 255.\n",
    "\n",
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_y[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    #r1, c1 = line(img_size//2,img_size//2,row1, col1)\n",
    "    #r2, c2 = line(row1, col1, row2, col2)\n",
    "    #r3, c3 = line(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1 *255\n",
    "    img[r2,c2] = val2 *255\n",
    "    img[r3,c3] = val3 *255\n",
    "    train_images_y[i][0] =gaussian_filter(img , sigma = 2) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille train_images_x', (30000, 1, 64, 64))\n",
      "('taille train_images_y', (30000, 1, 64, 64))\n",
      "('taille train_features', (30000, 2, 64, 64))\n"
     ]
    }
   ],
   "source": [
    "print('taille train_images_x', shape(train_images_x))\n",
    "print('taille train_images_y', shape(train_images_y))\n",
    "train_features = concatenate((train_images_x, train_images_y), 1)\n",
    "print('taille train_features', shape(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut rajouter une gaussienne au bout de l'effecteur pour le mettre en évidence\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa2f6ae9490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa2f6a01a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized Gated Field Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant le passge dans l'autoencodeur, les images sont factorisées en passant par une couche de percpetron. De même, la couche latente est factorisée.\n",
    "Les images sont de taille (128,128), on prend pour commencer 32 neurones. \n",
    "La sortie est de taille (3,1) (trois moteurs), on prend pour commencer une factorisation de taille (32,1) (synérgies motrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc un encodeur, un décodeur et 3 couches de perceptrons pour les deux images et pour les commandes motrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par construire un auto encodeur dont les entrées sont un tenseur de taille (32,1) et de sortie (32,1), pour garder la symétrie de la structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Input, Multiply\n",
    "from keras.layers import Conv2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.layers import Dot, Lambda, Concatenate, RepeatVector\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'encodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(None, 64)\n",
      "('out taille', (None, 1, 128))\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "input_shape = (2, input_size, input_size)\n",
    "latent_dim = 64 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (2, img_size, img_size, ), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,0,:,:])(inputs_xy)\n",
    "x = Reshape((1,img_size, img_size,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,1,:,:])(inputs_xy)\n",
    "y = Reshape((1,img_size, img_size,))(y)\n",
    "\n",
    "# on factorise chacune des images\n",
    "fx = Flatten()(x)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Flatten()(y)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "print(K.int_shape(fh))\n",
    "# on passe des synérgies motrices aux actionneurs\n",
    "#latent = Dense(3, activation = 'sigmoid',  name = 'latent_vector')(fh)\n",
    "#print('taille latent', K.int_shape(latent))\n",
    "\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "fh = Reshape((1,latent_dim,))(fh)\n",
    "#latent = Reshape((1,3,))(latent)\n",
    "\n",
    "out = Concatenate()([fx, fh])\n",
    "print('out taille', K.int_shape(out))\n",
    "\n",
    "encoder = Model(inputs = inputs_xy, outputs = out, name = 'encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille input', (None, 1, 128))\n",
      "('taille fx', (None, 64, 1))\n",
      "('taille tmp', (None, 64))\n",
      "('taille fhdec avant', (None, 64))\n",
      "('taille fhdec apres', (None, 64, 1))\n",
      "('taille matmuldec avant', (None, 64, 1))\n",
      "('taille matmuldec apres', (None, 64))\n",
      "('taille img dec', (None, 1, 64, 64))\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = Input(shape = (1,2*latent_dim,), name = 'decoder_input')\n",
    "print('taille input', K.int_shape(latent_inputs))\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:latent_dim])(latent_inputs)\n",
    "fxdec = Reshape((latent_dim,1,))(fxdec)\n",
    "print('taille fx', K.int_shape(fxdec))\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,latent_dim:])(latent_inputs)\n",
    "inp = Reshape((latent_dim,))(inp)\n",
    "print('taille tmp', K.int_shape(inp))\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(latent_dim, name='latent_fhdec')(inp)\n",
    "print('taille fhdec avant', K.int_shape(fhdec))\n",
    "fhdec = Reshape((latent_dim,1,))(fhdec)\n",
    "print('taille fhdec apres', K.int_shape(fhdec))\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "print('taille matmuldec avant', K.int_shape(matmuldec))\n",
    "matmuldec = Reshape((latent_dim,))(matmuldec)\n",
    "print('taille matmuldec apres', K.int_shape(matmuldec))\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(latent_dim, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(img_size*img_size, activation = 'relu', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((1,img_size, img_size,))(ydec)\n",
    "print('taille img dec', K.int_shape(ydec))\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs= ydec, name='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 2, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1, 128)            528576    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 1, 64, 64)         274560    \n",
      "=================================================================\n",
      "Total params: 803,136\n",
      "Trainable params: 803,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs_xy, decoder(encoder(inputs_xy)), name = \"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre des figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "plot_model(encoder, to_file='encoder.png')\n",
    "plot_model(decoder, to_file = 'decoder.png')\n",
    "plot_model(autoencoder, to_file = 'auto_encoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encodeur alternatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "input_shape = (2, input_size, input_size)\n",
    "latent_dim = 64 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (2, img_size, img_size, ), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,0,:,:])(inputs_xy)\n",
    "x = Reshape((1,img_size, img_size,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,1,:,:])(inputs_xy)\n",
    "y = Reshape((1,img_size, img_size,))(y)\n",
    "\n",
    "# on factorise chacune des images avec dex conv2D\n",
    "fx = Conv2D(filters = 32, kernel_size = 3, strides = 2, activation = 'relu', padding = \"same\")(x)\n",
    "fx = Flatten()(fx)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Conv2D(filters = 32, kernel_size = 3, strides = 2, activation = 'relu', padding = \"same\")(y)\n",
    "fy = Flatten()(fy)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "fh = Reshape((1,latent_dim,))(fh)\n",
    "out = Concatenate()([fx, fh])\n",
    "\n",
    "encoder_alt = Model(inputs = inputs_xy, outputs = out, name = 'encoder_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape = (1,2*latent_dim,), name = 'decoder_input')\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:latent_dim])(latent_inputs)\n",
    "fxdec = Reshape((latent_dim,1,))(fxdec)\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,latent_dim:])(latent_inputs)\n",
    "inp = Reshape((latent_dim,))(inp)\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(latent_dim, name='latent_fhdec')(inp)\n",
    "fhdec = Reshape((latent_dim,1,))(fhdec)\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "matmuldec = Reshape((latent_dim,))(matmuldec)\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(latent_dim, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(img_size*img_size, activation = 'relu', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((1,img_size, img_size,))(ydec)\n",
    "\n",
    "# on rajoute une couche de déconvolution \n",
    "ydec = Conv2DTranspose(filters= 32, kernel_size = 3, activation = 'relu', padding = 'same')(ydec)\n",
    "ydec = Conv2DTranspose(filters= 64, kernel_size = 3, activation = 'relu', padding = 'same')(ydec)\n",
    "decoder_alt = Model(latent_inputs, outputs= ydec, name='decoder_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 2, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "encoder_alt (Model)          (None, 1, 128)            172288    \n",
      "_________________________________________________________________\n",
      "decoder_alt (Model)          (None, 1, 64, 64)         311520    \n",
      "=================================================================\n",
      "Total params: 483,808\n",
      "Trainable params: 483,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_alt = Model(inputs_xy, decoder_alt(encoder_alt(inputs_xy)), name = \"autoencoder_alt\")\n",
    "autoencoder_alt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle sur des pairs d'images.\n",
    "On utilise une descente de gradient stochastique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5373 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5373 - val_acc: 0.0146\n",
      "Epoch 2/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5395 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5471 - val_acc: 0.0146\n",
      "Epoch 3/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5518 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5542 - val_acc: 0.0146\n",
      "Epoch 4/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5548 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5551 - val_acc: 0.0146\n",
      "Epoch 5/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5554 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5555 - val_acc: 0.0146\n",
      "Epoch 6/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5557 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5557 - val_acc: 0.0146\n",
      "Epoch 7/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5558 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5559 - val_acc: 0.0146\n",
      "Epoch 8/1000\n",
      "24000/24000 [==============================] - 19s 795us/step - loss: -0.7270 - mean_absolute_error: 124.5560 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5560 - val_acc: 0.0146\n",
      "Epoch 9/1000\n",
      "24000/24000 [==============================] - 14s 574us/step - loss: -0.7270 - mean_absolute_error: 124.5561 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5562 - val_acc: 0.0146\n",
      "Epoch 10/1000\n",
      "24000/24000 [==============================] - 14s 577us/step - loss: -0.7270 - mean_absolute_error: 124.5563 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5563 - val_acc: 0.0146\n",
      "Epoch 11/1000\n",
      "24000/24000 [==============================] - 14s 582us/step - loss: -0.7270 - mean_absolute_error: 124.5564 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5564 - val_acc: 0.0146\n",
      "Epoch 12/1000\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5565 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5565 - val_acc: 0.0146\n",
      "Epoch 13/1000\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5567 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5567 - val_acc: 0.0146\n",
      "Epoch 14/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5568 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5568 - val_acc: 0.0146\n",
      "Epoch 15/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5569 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5569 - val_acc: 0.0146\n",
      "Epoch 16/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5570 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5570 - val_acc: 0.0146\n",
      "Epoch 17/1000\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5572 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5572 - val_acc: 0.0146\n",
      "Epoch 18/1000\n",
      "24000/24000 [==============================] - 21s 889us/step - loss: -0.7270 - mean_absolute_error: 124.5573 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5573 - val_acc: 0.0146\n",
      "Epoch 19/1000\n",
      "24000/24000 [==============================] - 23s 946us/step - loss: -0.7270 - mean_absolute_error: 124.5574 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5574 - val_acc: 0.0146\n",
      "Epoch 20/1000\n",
      "24000/24000 [==============================] - 20s 827us/step - loss: -0.7270 - mean_absolute_error: 124.5575 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5575 - val_acc: 0.0146\n",
      "Epoch 21/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5577 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5577 - val_acc: 0.0146\n",
      "Epoch 22/1000\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5578 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5578 - val_acc: 0.0146\n",
      "Epoch 23/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5580 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5580 - val_acc: 0.0146\n",
      "Epoch 24/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5581 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5581 - val_acc: 0.0146\n",
      "Epoch 25/1000\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 26/1000\n",
      "24000/24000 [==============================] - 16s 676us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 27/1000\n",
      "24000/24000 [==============================] - 14s 578us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 28/1000\n",
      "24000/24000 [==============================] - 14s 574us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 29/1000\n",
      "24000/24000 [==============================] - 16s 661us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 30/1000\n",
      "24000/24000 [==============================] - 24s 987us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 31/1000\n",
      "24000/24000 [==============================] - 23s 976us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 32/1000\n",
      "24000/24000 [==============================] - 23s 971us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 33/1000\n",
      "24000/24000 [==============================] - 24s 992us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 34/1000\n",
      "24000/24000 [==============================] - 19s 773us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 35/1000\n",
      "24000/24000 [==============================] - 20s 853us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 36/1000\n",
      "24000/24000 [==============================] - 19s 773us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 37/1000\n",
      "24000/24000 [==============================] - 19s 795us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 38/1000\n",
      "24000/24000 [==============================] - 17s 704us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 39/1000\n",
      "24000/24000 [==============================] - 21s 869us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000\n",
      "24000/24000 [==============================] - 19s 810us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 41/1000\n",
      "24000/24000 [==============================] - 21s 861us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 42/1000\n",
      "24000/24000 [==============================] - 21s 857us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 43/1000\n",
      "24000/24000 [==============================] - 21s 866us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 44/1000\n",
      "24000/24000 [==============================] - 15s 604us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 45/1000\n",
      "24000/24000 [==============================] - 14s 568us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 46/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 47/1000\n",
      "24000/24000 [==============================] - 15s 617us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 48/1000\n",
      "24000/24000 [==============================] - 20s 824us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 49/1000\n",
      "24000/24000 [==============================] - 19s 808us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 50/1000\n",
      "24000/24000 [==============================] - 19s 812us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 51/1000\n",
      "24000/24000 [==============================] - 20s 826us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 52/1000\n",
      "24000/24000 [==============================] - 20s 854us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 53/1000\n",
      "24000/24000 [==============================] - 20s 826us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 54/1000\n",
      "24000/24000 [==============================] - 20s 814us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 55/1000\n",
      "24000/24000 [==============================] - 20s 852us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 56/1000\n",
      "24000/24000 [==============================] - 20s 840us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 57/1000\n",
      "24000/24000 [==============================] - 20s 849us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 58/1000\n",
      "24000/24000 [==============================] - 21s 868us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 59/1000\n",
      "24000/24000 [==============================] - 20s 834us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 60/1000\n",
      "24000/24000 [==============================] - 19s 812us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 61/1000\n",
      "24000/24000 [==============================] - 21s 868us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 62/1000\n",
      "24000/24000 [==============================] - 20s 846us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 63/1000\n",
      "24000/24000 [==============================] - 20s 839us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 64/1000\n",
      "24000/24000 [==============================] - 21s 881us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 65/1000\n",
      "24000/24000 [==============================] - 20s 852us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 66/1000\n",
      "24000/24000 [==============================] - 20s 818us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 67/1000\n",
      "24000/24000 [==============================] - 19s 810us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 68/1000\n",
      "24000/24000 [==============================] - 19s 805us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 69/1000\n",
      "24000/24000 [==============================] - 19s 806us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 70/1000\n",
      "24000/24000 [==============================] - 19s 808us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 71/1000\n",
      "24000/24000 [==============================] - 19s 810us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 72/1000\n",
      "24000/24000 [==============================] - 20s 850us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 73/1000\n",
      "24000/24000 [==============================] - 20s 836us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 74/1000\n",
      "24000/24000 [==============================] - 19s 809us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 75/1000\n",
      "24000/24000 [==============================] - 19s 811us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 76/1000\n",
      "24000/24000 [==============================] - 21s 855us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 77/1000\n",
      "24000/24000 [==============================] - 20s 822us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 78/1000\n",
      "24000/24000 [==============================] - 20s 847us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "24000/24000 [==============================] - 20s 843us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 80/1000\n",
      "24000/24000 [==============================] - 21s 858us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 81/1000\n",
      "24000/24000 [==============================] - 20s 819us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 82/1000\n",
      "24000/24000 [==============================] - 21s 862us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 83/1000\n",
      "24000/24000 [==============================] - 20s 833us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 84/1000\n",
      "24000/24000 [==============================] - 20s 815us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 85/1000\n",
      "24000/24000 [==============================] - 16s 685us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 86/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 87/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 88/1000\n",
      "24000/24000 [==============================] - 13s 552us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 89/1000\n",
      "24000/24000 [==============================] - 13s 560us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 90/1000\n",
      "24000/24000 [==============================] - 13s 558us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 91/1000\n",
      "24000/24000 [==============================] - 13s 558us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 92/1000\n",
      "24000/24000 [==============================] - 13s 553us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 93/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 94/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 95/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 96/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 97/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 98/1000\n",
      "24000/24000 [==============================] - 13s 556us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 99/1000\n",
      "24000/24000 [==============================] - 13s 552us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 100/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 101/1000\n",
      "24000/24000 [==============================] - 13s 553us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 102/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 103/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 104/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 105/1000\n",
      "24000/24000 [==============================] - 13s 556us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 106/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 107/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 108/1000\n",
      "24000/24000 [==============================] - 14s 585us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 109/1000\n",
      "24000/24000 [==============================] - 14s 582us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 110/1000\n",
      "24000/24000 [==============================] - 13s 558us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 111/1000\n",
      "24000/24000 [==============================] - 13s 555us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 112/1000\n",
      "24000/24000 [==============================] - 13s 561us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 113/1000\n",
      "24000/24000 [==============================] - 13s 562us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 114/1000\n",
      "24000/24000 [==============================] - 14s 569us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 115/1000\n",
      "24000/24000 [==============================] - 14s 572us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 116/1000\n",
      "24000/24000 [==============================] - 14s 578us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 19s 789us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 118/1000\n",
      "24000/24000 [==============================] - 21s 860us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 119/1000\n",
      "24000/24000 [==============================] - 21s 880us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 120/1000\n",
      "24000/24000 [==============================] - 18s 765us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 121/1000\n",
      "24000/24000 [==============================] - 15s 621us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 122/1000\n",
      "24000/24000 [==============================] - 20s 817us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 123/1000\n",
      "24000/24000 [==============================] - 21s 857us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 124/1000\n",
      "24000/24000 [==============================] - 20s 839us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 125/1000\n",
      "24000/24000 [==============================] - 15s 643us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 126/1000\n",
      "24000/24000 [==============================] - 20s 833us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 127/1000\n",
      "24000/24000 [==============================] - 20s 828us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 128/1000\n",
      "24000/24000 [==============================] - 14s 597us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 129/1000\n",
      "24000/24000 [==============================] - 20s 848us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 130/1000\n",
      "24000/24000 [==============================] - 20s 854us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 131/1000\n",
      "24000/24000 [==============================] - 17s 724us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 132/1000\n",
      "24000/24000 [==============================] - 21s 870us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 133/1000\n",
      "24000/24000 [==============================] - 20s 834us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 134/1000\n",
      "24000/24000 [==============================] - 16s 683us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 135/1000\n",
      "24000/24000 [==============================] - 14s 570us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 136/1000\n",
      "24000/24000 [==============================] - 14s 597us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 137/1000\n",
      "24000/24000 [==============================] - 14s 585us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 138/1000\n",
      "24000/24000 [==============================] - 15s 637us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 139/1000\n",
      "24000/24000 [==============================] - 21s 860us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 140/1000\n",
      "24000/24000 [==============================] - 20s 849us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 141/1000\n",
      "24000/24000 [==============================] - 18s 735us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 142/1000\n",
      "24000/24000 [==============================] - 17s 688us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 143/1000\n",
      "24000/24000 [==============================] - 14s 580us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 144/1000\n",
      "24000/24000 [==============================] - 15s 611us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 145/1000\n",
      "24000/24000 [==============================] - 19s 808us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 146/1000\n",
      "24000/24000 [==============================] - 21s 870us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 147/1000\n",
      "24000/24000 [==============================] - 20s 838us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 148/1000\n",
      "24000/24000 [==============================] - 21s 886us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 149/1000\n",
      "24000/24000 [==============================] - 21s 879us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 150/1000\n",
      "24000/24000 [==============================] - 20s 842us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 151/1000\n",
      "24000/24000 [==============================] - 14s 602us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 152/1000\n",
      "24000/24000 [==============================] - 21s 885us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 153/1000\n",
      "24000/24000 [==============================] - 21s 872us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 154/1000\n",
      "24000/24000 [==============================] - 20s 814us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 19s 808us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 156/1000\n",
      "24000/24000 [==============================] - 20s 838us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 157/1000\n",
      "24000/24000 [==============================] - 20s 835us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 158/1000\n",
      "24000/24000 [==============================] - 20s 813us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 159/1000\n",
      "24000/24000 [==============================] - 20s 814us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 160/1000\n",
      "24000/24000 [==============================] - 20s 815us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 161/1000\n",
      "24000/24000 [==============================] - 18s 759us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 162/1000\n",
      "24000/24000 [==============================] - 19s 780us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 163/1000\n",
      "24000/24000 [==============================] - 14s 595us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 164/1000\n",
      "24000/24000 [==============================] - 14s 566us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 165/1000\n",
      "24000/24000 [==============================] - 14s 575us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 166/1000\n",
      "24000/24000 [==============================] - 18s 735us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 167/1000\n",
      "24000/24000 [==============================] - 20s 852us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 168/1000\n",
      "24000/24000 [==============================] - 20s 816us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 169/1000\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 170/1000\n",
      "24000/24000 [==============================] - 13s 553us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 171/1000\n",
      "24000/24000 [==============================] - 14s 578us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 172/1000\n",
      "24000/24000 [==============================] - 14s 570us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 173/1000\n",
      "24000/24000 [==============================] - 17s 729us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 174/1000\n",
      "24000/24000 [==============================] - 20s 848us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 175/1000\n",
      "24000/24000 [==============================] - 20s 825us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 176/1000\n",
      "24000/24000 [==============================] - 15s 635us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 177/1000\n",
      "24000/24000 [==============================] - 14s 581us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 178/1000\n",
      "24000/24000 [==============================] - 17s 707us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 179/1000\n",
      "24000/24000 [==============================] - 21s 857us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 180/1000\n",
      "24000/24000 [==============================] - 20s 842us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 181/1000\n",
      "24000/24000 [==============================] - 15s 639us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 182/1000\n",
      "24000/24000 [==============================] - 13s 552us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 183/1000\n",
      "24000/24000 [==============================] - 13s 552us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 184/1000\n",
      "24000/24000 [==============================] - 13s 556us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 185/1000\n",
      "24000/24000 [==============================] - 13s 557us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 186/1000\n",
      "24000/24000 [==============================] - 14s 581us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 187/1000\n",
      "24000/24000 [==============================] - 18s 738us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 188/1000\n",
      "24000/24000 [==============================] - 19s 776us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 189/1000\n",
      "24000/24000 [==============================] - 21s 875us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 190/1000\n",
      "24000/24000 [==============================] - 21s 867us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 191/1000\n",
      "24000/24000 [==============================] - 18s 766us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 192/1000\n",
      "24000/24000 [==============================] - 14s 573us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 14s 574us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 194/1000\n",
      "24000/24000 [==============================] - 14s 596us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 195/1000\n",
      "24000/24000 [==============================] - 18s 733us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 196/1000\n",
      "24000/24000 [==============================] - 21s 864us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 197/1000\n",
      "24000/24000 [==============================] - 21s 860us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 198/1000\n",
      "24000/24000 [==============================] - 21s 880us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 199/1000\n",
      "24000/24000 [==============================] - 16s 681us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 200/1000\n",
      "24000/24000 [==============================] - 14s 578us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 201/1000\n",
      "24000/24000 [==============================] - 14s 588us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 202/1000\n",
      "24000/24000 [==============================] - 15s 631us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 203/1000\n",
      "24000/24000 [==============================] - 14s 584us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 204/1000\n",
      "24000/24000 [==============================] - 14s 579us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 205/1000\n",
      "24000/24000 [==============================] - 14s 595us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 206/1000\n",
      "24000/24000 [==============================] - 15s 643us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 207/1000\n",
      "24000/24000 [==============================] - 13s 554us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 208/1000\n",
      "24000/24000 [==============================] - 14s 563us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 209/1000\n",
      "24000/24000 [==============================] - 18s 759us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 210/1000\n",
      "24000/24000 [==============================] - 20s 849us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 211/1000\n",
      "24000/24000 [==============================] - 20s 832us/step - loss: -0.7270 - mean_absolute_error: 124.5582 - acc: 0.0151 - val_loss: -0.7594 - val_mean_absolute_error: 124.5582 - val_acc: 0.0146\n",
      "Epoch 212/1000\n",
      " 8608/24000 [=========>....................] - ETA: 12s - loss: -0.7266 - mean_absolute_error: 124.5582 - acc: 0.0152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-234be7fa23ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0mtrain_images_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                           epochs = 1000)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "autoencoder_alt.compile(loss = 'kullback_leibler_divergence', \n",
    "                    optimizer = 'sgd', \n",
    "                    metrics = ['mae', 'acc'])\n",
    "\n",
    "history = autoencoder_alt.fit(train_features,\n",
    "                          train_images_y,\n",
    "                          validation_split = 0.2,\n",
    "                          epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Décodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_decoded = autoencoder.predict(train_features)\n",
    "imshow(x_decoded[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "rows, cols = 10, 30\n",
    "num = rows * cols\n",
    "imgs = np.concatenate([train_images_x[:num], train_images_y[:num], x_decoded[:num]])\n",
    "imgs = imgs.reshape((rows * 3, cols, img_size, img_size))\n",
    "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
    "imgs = imgs.reshape((rows * 3, -1, img_size, img_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "imgs = (imgs *255 ).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Original images: top rows, '\n",
    "          'Corrupted Input: middle rows, '\n",
    "          'Denoised Input:  third rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(x_decoded[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
