{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation visuelle pour reconstruction d'image corporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "L'objectif est d'améliorer le code de network2_01.py. \n",
    "Plusieurs pistes d'amélioration sont possibles:\n",
    "1. Utiliser un produit tensoriel plutôt qu'un produit terme à terme.\n",
    "2. Différencier la cible de la main.\n",
    "3. Intégerer tf.\n",
    "4. changer la répartition des points. \n",
    "\n",
    "Je m'inspire de l'article de Memisevic, Gradient-based learning of higher-order image features et de son code gatedAutoencoder.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et setup\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from matplotlib.pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from drawnow import *\n",
    "from skimage.draw import line, line_aa\n",
    "\n",
    "import time \n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import cv2\n",
    "import cPickle as pickle\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size':16})\n",
    "to_backup = True\n",
    "timeframe = time.strftime('%Y%m%d%H%M%S')\n",
    "L1 = 8\n",
    "L2 = 4\n",
    "L3 = 2\n",
    "\n",
    "nb_posture = 300\n",
    "nb_command = 100\n",
    "nb_joint = 3\n",
    "nb_data = nb_command*nb_posture\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On génère n postures différentes aléatoirement, X.\n",
    "2. On génère m commandes aléatoirement, H. \n",
    "3. On applique chaque commande à chaque posture et on obtient des nouvelles postures Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des postures initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randrange(n , vmin, vmax):\n",
    "    return (vmax-vmin)*rand(n) + vmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posture = zeros((nb_posture, 3))\n",
    "posture[:,0] = randrange(nb_posture, 0, pi)\n",
    "posture[:,1] = randrange(nb_posture, 0, pi)\n",
    "posture[:,2] =randrange(nb_posture, 0, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "[2.39809887 0.08315459 2.06592509]\n"
     ]
    }
   ],
   "source": [
    "print(shape(posture))\n",
    "print(posture[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des commandes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = zeros((nb_command, 3))\n",
    "command[:,0] = randrange(nb_command, 0, 1)*0.9\n",
    "command[:,1] = randrange(nb_command, 0, 1)*0.9\n",
    "command[:,2] =randrange(nb_command, 0, 1)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[0.09861677 0.88114352 0.07639193]\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(shape(command))\n",
    "print(command[0])\n",
    "print(randint(0,nb_command-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = zeros((nb_data, 1, 3))\n",
    "train_data_y = zeros((nb_data, 1, 3))\n",
    "train_data_h = zeros((nb_data, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "(30000, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x[0][0])\n",
    "print(shape(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_x[idx] = posture[i]\n",
    "        idx = idx + 1\n",
    "\n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_y[idx] = posture[i]  + command[j]\n",
    "        idx = idx + 1\n",
    "        \n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_h[idx] = command[j]\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data_x 0 0 ', array([2.39809887, 0.08315459, 2.06592509]))\n",
      "('train_data_h 0 0 ', array([0.09861677, 0.88114352, 0.07639193]))\n",
      "('train_data_y 0 0 ', array([2.49671564, 0.96429811, 2.14231702]))\n",
      "y = x + h\n"
     ]
    }
   ],
   "source": [
    "print('train_data_x 0 0 ', train_data_x[0][0])\n",
    "print('train_data_h 0 0 ', train_data_h[0][0])\n",
    "print('train_data_y 0 0 ', train_data_y[0][0])\n",
    "print('y = x + h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des images associées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "train_images_x = zeros((nb_data, 1, img_size, img_size ), dtype = uint8)\n",
    "train_images_y = zeros((nb_data, 1, img_size, img_size ), dtype = uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_x[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_x[i][0] = img \n",
    "\n",
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_y[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_y[i][0] = img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille train_images_x', (30000, 1, 32, 32))\n",
      "('taille train_images_y', (30000, 1, 32, 32))\n",
      "('taille train_features', (30000, 2, 32, 32))\n"
     ]
    }
   ],
   "source": [
    "print('taille train_images_x', shape(train_images_x))\n",
    "print('taille train_images_y', shape(train_images_y))\n",
    "train_features = concatenate((train_images_x, train_images_y), 1)\n",
    "print('taille train_features', shape(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut rajouter une gaussienne au bout de l'effecteur pour le mettre en évidence\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "    x = arange(0, size, 1, float)\n",
    "    y = x[:,newaxis]\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]    \n",
    "    return exp(-4*log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe090b5490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe06184a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized Gated Field Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant le passge dans l'autoencodeur, les images sont factorisées en passant par une couche de percpetron. De même, la couche latente est factorisée.\n",
    "Les images sont de taille (128,128), on prend pour commencer 32 neurones. \n",
    "La sortie est de taille (3,1) (trois moteurs), on prend pour commencer une factorisation de taille (32,1) (synérgies motrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc un encodeur, un décodeur et 3 couches de perceptrons pour les deux images et pour les commandes motrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par construire un auto encodeur dont les entrées sont un tenseur de taille (32,1) et de sortie (32,1), pour garder la symétrie de la structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Input, Multiply\n",
    "from keras.layers import Conv2D, Flatten, Reshape\n",
    "from keras.layers import Dot, Lambda, Concatenate, RepeatVector\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'encodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille initiale inputs_xy', (None, 2, 32, 32))\n",
      "('taille intiale de x', (None, 1, 32, 32))\n",
      "('taille initiale de y', (None, 1, 32, 32))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "('taille inter fx', (None, 32, 1))\n",
      "('taille inter fy', (None, 32, 1))\n",
      "('taill inter matmul', (None, 32, 1))\n",
      "('out taille', (None, 1, 64))\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xy (InputLayer)                 (None, 2, 32, 32)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32)       0           xy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 32, 32)       0           xy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 32, 32)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 32, 32)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1024)         0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_fx (Dense)               (None, 32)           32800       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_fy (Dense)               (None, 32)           32800       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 32, 1)        0           latent_fx[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 32, 1)        0           latent_fy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 32, 1)        0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "latent_fh (Dense)               (None, 32)           1056        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 32)           0           latent_fh[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 32)        0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 32)        0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 64)        0           reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 66,656\n",
      "Trainable params: 66,656\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "input_shape = (2, input_size, input_size)\n",
    "latent_dim = 32 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (2, img_size, img_size,  ), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,0,:,:])(inputs_xy)\n",
    "x = Reshape((1,img_size, img_size,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,1,:,:])(inputs_xy)\n",
    "y = Reshape((1,img_size, img_size,))(y)\n",
    "\n",
    "print('taille initiale inputs_xy', K.int_shape(inputs_xy))\n",
    "print('taille intiale de x', K.int_shape(x))\n",
    "print('taille initiale de y', K.int_shape(y))\n",
    "\n",
    "# on factorise chacune des images\n",
    "fx = Flatten()(x)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Flatten()(y)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "print('taille inter fx', K.int_shape(fx))\n",
    "print('taille inter fy', K.int_shape(fy))\n",
    "print('taill inter matmul', K.int_shape(matmul))\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "\n",
    "# on passe des synérgies motrices aux actionneurs\n",
    "#latent = Dense(3, activation = 'sigmoid',  name = 'latent_vector')(fh)\n",
    "#print('taille latent', K.int_shape(latent))\n",
    "\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "fh = Reshape((1,latent_dim,))(fh)\n",
    "#latent = Reshape((1,3,))(latent)\n",
    "\n",
    "out = Concatenate()([fx, fh])\n",
    "print('out taille', K.int_shape(out))\n",
    "\n",
    "encoder = Model(inputs = inputs_xy, outputs = out, name = 'encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille input', (None, 1, 64))\n",
      "('taille fx', (None, 32, 1))\n",
      "('taille tmp', (None, 32))\n",
      "('taille fhdec avant', (None, 32))\n",
      "('taille fhdec apres', (None, 32, 1))\n",
      "('taille matmuldec avant', (None, 32, 1))\n",
      "('taille matmuldec apres', (None, 32))\n",
      "('taille img dec', (None, 1, 32, 32))\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, 1, 64)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 32)        0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 32)           0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 32)        0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "latent_fhdec (Dense)            (None, 32)           1056        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 32, 1)        0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 32, 1)        0           latent_fhdec[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 32, 1)        0           reshape_8[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 32)           0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "latent_fydec (Dense)            (None, 32)           1056        reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "y_recon (Dense)                 (None, 1024)         33792       latent_fydec[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 32, 32)    0           y_recon[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 35,904\n",
      "Trainable params: 35,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = Input(shape = (1,2*latent_dim,), name = 'decoder_input')\n",
    "print('taille input', K.int_shape(latent_inputs))\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:latent_dim])(latent_inputs)\n",
    "fxdec = Reshape((latent_dim,1,))(fxdec)\n",
    "print('taille fx', K.int_shape(fxdec))\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,latent_dim:])(latent_inputs)\n",
    "inp = Reshape((latent_dim,))(inp)\n",
    "print('taille tmp', K.int_shape(inp))\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(latent_dim, name='latent_fhdec')(inp)\n",
    "print('taille fhdec avant', K.int_shape(fhdec))\n",
    "fhdec = Reshape((latent_dim,1,))(fhdec)\n",
    "print('taille fhdec apres', K.int_shape(fhdec))\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "print('taille matmuldec avant', K.int_shape(matmuldec))\n",
    "matmuldec = Reshape((latent_dim,))(matmuldec)\n",
    "print('taille matmuldec apres', K.int_shape(matmuldec))\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(latent_dim, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(img_size*img_size, activation = 'softmax', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((1,img_size, img_size,))(ydec)\n",
    "print('taille img dec', K.int_shape(ydec))\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs= ydec, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 2, 32, 32)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1, 64)             66656     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 1, 32, 32)         35904     \n",
      "=================================================================\n",
      "Total params: 102,560\n",
      "Trainable params: 102,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs_xy, decoder(encoder(inputs_xy)), name = \"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre des figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "plot_model(encoder, to_file='encoder.png')\n",
    "plot_model(decoder, to_file = 'decoder.png')\n",
    "plot_model(autoencoder, to_file = 'auto_encoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle sur des pairs d'images.\n",
    "On utilise une descente de gradient stochastique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "24000/24000 [==============================] - 2s 97us/step - loss: 655.3539 - mean_absolute_error: 3.4250 - acc: 0.7485 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 2/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 3/100\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 4/100\n",
      "24000/24000 [==============================] - 2s 84us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 5/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 6/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 7/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 8/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 9/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 10/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 11/100\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 12/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 13/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 14/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 15/100\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 16/100\n",
      "24000/24000 [==============================] - 2s 91us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 17/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 18/100\n",
      "24000/24000 [==============================] - 2s 90us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 19/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 20/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 21/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 22/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 23/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 24/100\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 25/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 26/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 27/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 28/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 29/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 30/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 31/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 32/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 33/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 34/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 35/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 36/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 37/100\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 38/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 40/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 41/100\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 42/100\n",
      "24000/24000 [==============================] - 2s 84us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 43/100\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 44/100\n",
      "24000/24000 [==============================] - 2s 83us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 45/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 46/100\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 655.3516 - mean_absolute_error: 3.4250 - acc: 0.7502 - val_loss: 654.4574 - val_mean_absolute_error: 3.4039 - val_acc: 0.7411\n",
      "Epoch 47/100\n",
      " 1440/24000 [>.............................] - ETA: 1s - loss: 652.6811 - mean_absolute_error: 3.4138 - acc: 0.7516"
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr = 0.1, momentum = 0.0)\n",
    "\n",
    "autoencoder.compile(loss = 'mse', \n",
    "                    optimizer = sgd, \n",
    "                    metrics = ['mae', 'acc'])\n",
    "\n",
    "history = autoencoder.fit(train_features,\n",
    "                          train_images_y,\n",
    "                          validation_split = 0.2,\n",
    "                          epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
