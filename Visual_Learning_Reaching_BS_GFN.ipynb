{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation visuelle pour reconstruction d'image corporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "L'objectif est d'améliorer le code de network2_01.py. \n",
    "Plusieurs pistes d'amélioration sont possibles:\n",
    "1. Utiliser un produit tensoriel plutôt qu'un produit terme à terme.\n",
    "2. Différencier la cible de la main.\n",
    "3. Intégerer tf.\n",
    "4. changer la répartition des points. \n",
    "\n",
    "Je m'inspire de l'article de Memisevic, Gradient-based learning of higher-order image features et de son code gatedAutoencoder.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et setup\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from matplotlib.pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from drawnow import *\n",
    "from skimage.draw import line, line_aa\n",
    "\n",
    "import time \n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import cv2\n",
    "import cPickle as pickle\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size':16})\n",
    "to_backup = True\n",
    "timeframe = time.strftime('%Y%m%d%H%M%S')\n",
    "L1 = 32\n",
    "L2 = 16\n",
    "L3 = 8\n",
    "\n",
    "nb_posture = 30\n",
    "nb_command = 10\n",
    "nb_joint = 3\n",
    "nb_data = nb_command*nb_posture\n",
    "img_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On génère n postures différentes aléatoirement, X.\n",
    "2. On génère m commandes aléatoirement, H. \n",
    "3. On applique chaque commande à chaque posture et on obtient des nouvelles postures Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des postures initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randrange(n , vmin, vmax):\n",
    "    return (vmax-vmin)*rand(n) + vmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posture = zeros((nb_posture, 3))\n",
    "posture[:,0] = randrange(nb_posture, 0, pi)\n",
    "posture[:,1] = randrange(nb_posture, 0, pi)\n",
    "posture[:,2] =randrange(nb_posture, 0, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n",
      "[2.4133671  2.96701566 0.13842798]\n"
     ]
    }
   ],
   "source": [
    "print(shape(posture))\n",
    "print(posture[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des commandes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = zeros((nb_command, 3))\n",
    "command[:,0] = randrange(nb_command, 0, 1)\n",
    "command[:,1] = randrange(nb_command, 0, 1)\n",
    "command[:,2] =randrange(nb_command, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "[0.09706473 0.27078623 0.4849155 ]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(shape(command))\n",
    "print(command[0])\n",
    "print(randint(0,nb_command-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = zeros((nb_data, 1, 3))\n",
    "train_data_y = zeros((nb_data, 1, 3))\n",
    "train_data_h = zeros((nb_data, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "(300, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x[0][0])\n",
    "print(shape(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_x[idx] = posture[i]\n",
    "        idx = idx + 1\n",
    "\n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_y[idx] = posture[i]  + command[j]\n",
    "        idx = idx + 1\n",
    "        \n",
    "idx = 0 \n",
    "for i in range(nb_posture):\n",
    "    for j in range(nb_command):\n",
    "        train_data_h[idx] = command[j]\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data_x 0 0 ', array([2.4133671 , 2.96701566, 0.13842798]))\n",
      "('train_data_h 0 0 ', array([0.09706473, 0.27078623, 0.4849155 ]))\n",
      "('train_data_y 0 0 ', array([2.51043183, 3.23780189, 0.62334348]))\n",
      "y = x + h\n"
     ]
    }
   ],
   "source": [
    "print('train_data_x 0 0 ', train_data_x[0][0])\n",
    "print('train_data_h 0 0 ', train_data_h[0][0])\n",
    "print('train_data_y 0 0 ', train_data_y[0][0])\n",
    "print('y = x + h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des images associées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_x = zeros((nb_data, 1, 128, 128), dtype = uint8)\n",
    "train_images_y = zeros((nb_data, 1, 128, 128), dtype = uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_x[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(img_size//2,img_size//2,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_x[i][0] = img \n",
    "\n",
    "for i in range(nb_data):\n",
    "    img = zeros((img_size,img_size), dtype = uint8)\n",
    "    angle = train_data_y[i][0] \n",
    "    row1, col1 = img_size//2 + int(floor(L1*sin(angle[0]))), img_size//2 + int(floor(L1*cos(angle[0])))\n",
    "    row2, col2 =  int(floor(L2*sin(angle[1]))) + row1, col1 + int(floor(L2*cos(angle[1])))\n",
    "    row3, col3 = int(floor(L3*sin(angle[2])))+ row2, col2 +  int(floor(L3*cos(angle[2])))\n",
    "    r1, c1, val1 = line_aa(64,64,row1, col1)\n",
    "    r2, c2, val2 = line_aa(row1, col1, row2, col2)\n",
    "    r3, c3, val3 = line_aa(row2, col2, row3 , col3)\n",
    "    img[r1,c1] = val1*255\n",
    "    img[r2,c2] = val2*255\n",
    "    img[r3,c3] = val3*255\n",
    "    train_images_y[i][0] = img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut rajouter une gaussienne au bout de l'effecteur pour le mettre en évidence\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "    x = arange(0, size, 1, float)\n",
    "    y = x[:,newaxis]\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]    \n",
    "    return exp(-4*log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2d0a73490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2d018cfd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_images_y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized Gated Field Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant le passge dans l'autoencodeur, les images sont factorisées en passant par une couche de percpetron. De même, la couche latente est factorisée.\n",
    "Les images sont de taille (128,128), on prend pour commencer 32 neurones. \n",
    "La sortie est de taille (3,1) (trois moteurs), on prend pour commencer une factorisation de taille (32,1) (synérgies motrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc un encodeur, un décodeur et 3 couches de perceptrons pour les deux images et pour les commandes motrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par construire un auto encodeur dont les entrées sont un tenseur de taille (32,1) et de sortie (32,1), pour garder la symétrie de la structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Input, Multiply\n",
    "from keras.layers import Conv2D, Flatten, Reshape\n",
    "from keras.layers import Dot, Lambda, Concatenate, RepeatVector\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'encodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille initiale inputs_xy', (None, 128, 128, 2))\n",
      "('taille intiale de x', (None, 128, 128, 1))\n",
      "('taille initiale de y', (None, 128, 128, 1))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "('taille inter fx', (None, 30, 1))\n",
      "('taille inter fy', (None, 30, 1))\n",
      "('taill inter matmul', (None, 30, 1))\n",
      "('taille latent', (None, 3))\n",
      "('out taille', (None, 1, 33))\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xy (InputLayer)                 (None, 128, 128, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128)     0           xy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128)     0           xy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 128, 1)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 128, 128, 1)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16384)        0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16384)        0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_fx (Dense)               (None, 30)           491550      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_fy (Dense)               (None, 30)           491550      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 30, 1)        0           latent_fx[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 30, 1)        0           latent_fy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 30, 1)        0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 30)           0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "latent_fh (Dense)               (None, 30)           930         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 30)           0           latent_fh[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_vector (Dense)           (None, 3)            93          reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 30)        0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 3)         0           latent_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 33)        0           reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 984,123\n",
      "Trainable params: 984,123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "input_shape = (input_size, input_size, 2)\n",
    "latent_dim = 30 # plus facile pour la concaténation des outputs...\n",
    "\n",
    "# on donne en entrée des pairs d'images\n",
    "inputs_xy = Input(shape = (128,128,2,), name = 'xy')\n",
    "\n",
    "# on sépare chacune des images\n",
    "x = Lambda(lambda x: x[:,:,:,0])(inputs_xy)\n",
    "x = Reshape((128,128,1,))(x)\n",
    "\n",
    "y = Lambda(lambda x: x[:,:,:,1])(inputs_xy)\n",
    "y = Reshape((128,128,1,))(y)\n",
    "\n",
    "print('taille initiale inputs_xy', K.int_shape(inputs_xy))\n",
    "print('taille intiale de x', K.int_shape(x))\n",
    "print('taille initiale de y', K.int_shape(y))\n",
    "\n",
    "# on factorise chacune des images\n",
    "fx = Flatten()(x)\n",
    "fx = Dense(latent_dim, activation = 'relu', name = 'latent_fx')(fx)\n",
    "fx = Reshape((latent_dim,1,))(fx)\n",
    "\n",
    "fy = Flatten()(y)\n",
    "fy = Dense(latent_dim, activation = 'relu', name = 'latent_fy')(fy)\n",
    "fy = Reshape((latent_dim,1,))(fy)\n",
    "\n",
    "# on multiplie les deux factorisations, TODO mieux si produit tensoriel\n",
    "matmul = Multiply()([fx, fy])\n",
    "\n",
    "print('taille inter fx', K.int_shape(fx))\n",
    "print('taille inter fy', K.int_shape(fy))\n",
    "print('taill inter matmul', K.int_shape(matmul))\n",
    "\n",
    "# on passe le tout dans une couche de perceptrons pour obtenir les synérgies motrices\n",
    "x = Flatten()(matmul)\n",
    "fh = Dense(latent_dim, name = 'latent_fh')(x)\n",
    "fh = Reshape((latent_dim,))(fh)\n",
    "\n",
    "# on passe des synérgies motrices aux actionneurs\n",
    "latent = Dense(3, activation = 'sigmoid',  name = 'latent_vector')(fh)\n",
    "print('taille latent', K.int_shape(latent))\n",
    "\n",
    "\n",
    "# tricks pour pouvoir passer fx et latent en outputs\n",
    "fx = Reshape((1,latent_dim,))(fx)\n",
    "latent = Reshape((1,3,))(latent)\n",
    "\n",
    "out = Concatenate()([fx, latent])\n",
    "print('out taille', K.int_shape(out))\n",
    "\n",
    "encoder = Model(inputs = inputs_xy, outputs = out, name = 'encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('taille input', (None, 1, 33))\n",
      "('taille fx', (None, 30, 1))\n",
      "('taille tmp', (None, 3))\n",
      "('taille fhdec avant', (None, 30))\n",
      "('taille fhdec apres', (None, 30, 1))\n",
      "('taille matmuldec avant', (None, 30, 1))\n",
      "('taille matmuldec apres', (None, 30))\n",
      "('taille img dec', (None, 128, 128, 1))\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, 1, 33)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 3)         0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 3)            0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 30)        0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "latent_fhdec (Dense)            (None, 30)           120         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 30, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 30, 1)        0           latent_fhdec[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 30, 1)        0           reshape_13[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 30)           0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "latent_fydec (Dense)            (None, 30)           930         reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "y_recon (Dense)                 (None, 16384)        507904      latent_fydec[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 128, 128, 1)  0           y_recon[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 508,954\n",
      "Trainable params: 508,954\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = Input(shape = (1,33,), name = 'decoder_input')\n",
    "print('taille input', K.int_shape(latent_inputs))\n",
    "\n",
    "# on déballe la factorisation en x\n",
    "fxdec = Lambda(lambda x: x[:,:,:30])(latent_inputs)\n",
    "fxdec = Reshape((30,1,))(fxdec)\n",
    "print('taille fx', K.int_shape(fxdec))\n",
    "\n",
    "# on déballe les commandes motrices\n",
    "inp = Lambda(lambda x: x[:,:,30:])(latent_inputs)\n",
    "inp = Reshape((3,))(inp)\n",
    "print('taille tmp', K.int_shape(inp))\n",
    "\n",
    "# on fait passer les commandes motrices dans la couche de perceptrons\n",
    "fhdec = Dense(30, name='latent_fhdec')(inp)\n",
    "print('taille fhdec avant', K.int_shape(fhdec))\n",
    "fhdec = Reshape((30,1,))(fhdec)\n",
    "print('taille fhdec apres', K.int_shape(fhdec))\n",
    "\n",
    "# on mutliplie les deux représentations\n",
    "matmuldec = Multiply()([fxdec, fhdec])\n",
    "print('taille matmuldec avant', K.int_shape(matmuldec))\n",
    "matmuldec = Reshape((30,))(matmuldec)\n",
    "print('taille matmuldec apres', K.int_shape(matmuldec))\n",
    "\n",
    "# on en déduit une factorisation \n",
    "fydec = Dense(30, name = 'latent_fydec')(matmuldec)\n",
    "\n",
    "# on déduit l'image de départ de cette factorisation\n",
    "ydec = Dense(16384, activation = 'softmax', name = 'y_recon')(fydec)\n",
    "ydec = Reshape((128,128,1,))(ydec)\n",
    "print('taille img dec', K.int_shape(ydec))\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs= ydec, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xy (InputLayer)              (None, 128, 128, 2)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1, 33)             984123    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 128, 128, 1)       508954    \n",
      "=================================================================\n",
      "Total params: 1,493,077\n",
      "Trainable params: 1,493,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs_xy, decoder(encoder(inputs_xy)), name = \"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "plot_model(encoder, to_file='encoder.png')\n",
    "plot_model(decoder, to_file = 'decoder.png')\n",
    "plot_model(autoencoder, to_file = 'auto_encoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
